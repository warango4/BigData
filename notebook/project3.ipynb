{"cells":[{"cell_type":"code","source":["from pyspark.sql.functions import udf, col, lower, regexp_replace, concat_ws, trim\nfrom pyspark.ml.feature import Tokenizer, StopWordsRemover\nfrom pyspark.sql.types import ArrayType, StringType, IntegerType\n\nfile_location = \"dbfs:///FileStore/tables/all-news/*.csv\"\nfile_type = \"csv\"\n\n# CSV options\ninfer_schema = \"false\"\nfirst_row_is_header = \"true\"\ndelimiter = \",\"\n\n# The applied options are for CSV files. For other file types, these will be ignored.\ndf_file = spark.read.format(file_type) \\\n  .option(\"inferSchema\", infer_schema) \\\n  .option(\"header\", first_row_is_header) \\\n  .option(\"sep\", delimiter) \\\n  .load(file_location) \\\n  .select('id', 'title', 'content') \\\n  .na.drop()\n\n# Delete punctuation\ndf_cleaned = df_file.select('id', (lower(regexp_replace('title', \"[^a-zA-Z\\\\s]\", \" \")).alias('title')), \\\n                                  (lower(regexp_replace('content', \"[^a-zA-Z\\\\s]\", \" \")).alias('content')))\n\ndf_cleaned = df_cleaned.select('id', (regexp_replace('title', \"[!-~]?\\\\b[\\\\w]\\\\b[!-~]?\", \" \")).alias('title'), \\\n                                     (regexp_replace('content', \"[!-~]?\\\\b[\\\\w]\\\\b[!-~]?\", \" \")).alias('content'))\n\ndf_cleaned = df_cleaned.select('id', (regexp_replace(trim(col('title')), \" +\", \" \")).alias('title'), \\\n                                     (regexp_replace(trim(col('content')), \" +\", \" \")).alias('content'))\n\n# Tokenize title\ntitle_tokenizer = Tokenizer(inputCol='title', outputCol='tokenized_title')\ndf_tokenized_title = title_tokenizer.transform(df_cleaned).select('id', 'tokenized_title', 'content')\n\n# Remove stopwords from title\nstopwords_title_remover = StopWordsRemover(inputCol='tokenized_title', outputCol='cleaned_title')\ndf_title_removed_stopwords = stopwords_title_remover.transform(df_tokenized_title).select('id', 'cleaned_title', 'content')\n\n# Clean words whose lenght is less than 1\nfilter_length_udf = udf(lambda row: [x for x in row if len(x) > 1], ArrayType(StringType()))\ndf_final_title = df_title_removed_stopwords.withColumn('cleaned_title', filter_length_udf(col('cleaned_title')))\n\n# Tokenize content\ncontent_tokenizer = Tokenizer(inputCol='content', outputCol='tokenized_content')\ndf_tokenized_content = content_tokenizer.transform(df_final_title).select('id', 'cleaned_title', 'tokenized_content')\n\n# Remove stopwords from content\nstopwords_remover = StopWordsRemover(inputCol='tokenized_content', outputCol='cleaned_content')\ndf_removed_stopwords = stopwords_remover.transform(df_tokenized_content).select('id', 'cleaned_title', 'cleaned_content')\n\n# Filter length in content\ndf_final = df_removed_stopwords.withColumn('cleaned_content', filter_length_udf(col('cleaned_content')))\n\n# Make title and content strings and id an integer\ndf_final = df_final.withColumn('cleaned_title', concat_ws(\" \", 'cleaned_title')) \\\n           .withColumn('cleaned_content', concat_ws(\" \", 'cleaned_content')) \\\n           .withColumn('id', df_final['id'].cast(IntegerType())) \\\n           .select('id', col('cleaned_title').alias('title'), col('cleaned_content').alias('content')) \n           \n#display(df_final)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":1},{"cell_type":"code","source":["articles_rdd = df_final.rdd.map(lambda x: (x['id'], x['title'], x['content']))\n#print(articles_rdd.take(5))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"code","source":["# Inverted index\n\nimport itertools\nimport operator\n\ndef accumulate(l):\n  it = itertools.groupby(l, operator.itemgetter(0))\n  for key, subiter in it:\n     yield key, sum(item[1] for item in subiter)\n\n\ninverted_index_rdd = articles_rdd.flatMap(lambda line: [(word , (line[0], 1)) for word in (line[1] + \" \" + line[2]).split(\" \")]) \\\n                                 .groupByKey() \\\n                                 .map(lambda word: (word[0], list(word[1]))) \\\n                                 .map(lambda lista: (lista[0], sorted(list(accumulate(lista[1])), key = lambda x: -x[1]))) \\\n                                 .cache()\n\n\n#inverted_index_rdd.take(5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"code","source":["# Online\n\nnew_df = df_file.withColumn('id', df_file['id'].cast(IntegerType())) \\\n                .select('id', 'title', 'content') \n\nfile_rdd = new_df.rdd.map(lambda x: (x['id'], x['title']))\nfile_map = file_rdd.collectAsMap()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"code","source":["dbutils.widgets.text(\"word\", \"Please enter word to search\")\ndbutils.widgets.text(\"search\", \"Please enter id to search\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"code","source":["toSearch = str(dbutils.widgets.get(\"word\"))\nfinal_result = inverted_index_rdd.filter(lambda x, toSearch=toSearch: x[0] == toSearch) \\\n                                 .flatMap(lambda result: result[1])\n\nfinal_result_list = final_result.collect()\n#print(final_result_list)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"code","source":["def printing_result(): \n  cont = 0\n  maximum = 5\n  for i in final_result_list:\n    if cont == maximum: break\n    if i[0] != None:\n      cont += 1\n      yield i[1], list(((k, v) for k, v in file_map.items() if k == i[0]))\n\nprint(list(printing_result()))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[(37, [(157218, &apos;Peru 0-0 Colombia (Colombia win 4-2 on penalties): Copa América – as it happened&apos;)]), (35, [(21637, &apos;The Secret History of Colombia’s Paramilitaries and the U.S. War on Drugs - The New York Times&apos;)]), (18, [(22019, &apos;Colombian Opposition to Peace Deal Feeds Off Gay Rights Backlash - The New York Times&apos;)]), (18, [(80078, &apos;The End of Colombian Exceptionalism&apos;)]), (17, [(172524, &apos;Can Colombia Finally Fix Its Split Personality? &apos;)])]\n</div>"]}}],"execution_count":7},{"cell_type":"code","source":["from collections import defaultdict\n\ndef accumulate2(l):\n  d = defaultdict(list)\n  for k, *v in l:\n    d[k].append(sum(v))\n  for k in d.keys():\n    yield k, len(d[k])\n\nnews_rdd = articles_rdd.flatMap(lambda line: [(line[0] , (word, 1)) for word in (line[1] + \" \" + line[2]).split(\" \")]) \\\n                       .groupByKey() \\\n                       .map(lambda word: (word[0], list(word[1]))) \\\n                       .filter(lambda x: x[0] != None) \\\n                       .map(lambda lista: (lista[0], sorted(list(accumulate2(lista[1])), key = lambda x: -x[1]))) \\\n                       .cache()\n\n#news_rdd.count()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":8},{"cell_type":"code","source":["from functools import reduce\n\nid_search = int(dbutils.widgets.get(\"search\"))\nif not id_search in file_map or id_search == None: print(\"Not found\")\nelse:\n  new_title = file_map[id_search]\n  in_new_rdd = news_rdd.filter(lambda x, id_search=id_search: x[0] == id_search)  \n  in_new_list = in_new_rdd.collect()\n  \n  def news_similarity2(rdd_other_news):\n    list1 = in_new_list[0][1]\n    list2 = rdd_other_news[1]\n    list3 = []\n    for value in list1:\n      for v in list2:\n        if value[0] == v[0]: list3.append(value[0]) \n    union = list1 + list2\n    distance_list = list(filter((lambda x, list3=list3: x[0] in list3), union))\n    if len(distance_list) != 0:\n      last_result = reduce(lambda a, b: (a[0], a[1] + b[1]) if a[0] != \"\" and b[0] != \"\" else 0, distance_list)[1]\n      result = [rdd_other_news[0], last_result, len(list3)]\n    else:\n      result = [rdd_other_news[0], 0, 0]\n    return result\n\n  other_news = news_rdd.filter(lambda x, id_search=id_search: x[0] != id_search) \n  sim_news = other_news.map(news_similarity2) \\\n                          .sortBy(lambda x: -x[1])\n                          \n  sim_news_df = sim_news.toDF([\"id\",\"similarity\",\"words\"])\n  #display(sim_news_df)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":9},{"cell_type":"code","source":["aux = sim_news.take(5)\nnews_result_final = []\nfor i in aux:\n  news_result_final.append(i[0])\nprint(id_search, new_title, news_result_final)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">167499 Reporting On The Zika Virus Means Getting Up Close And Personal [36274, 51752, 18600, 25704, 24476]\n</div>"]}}],"execution_count":10}],"metadata":{"name":"TETProject3Final","notebookId":4013226145831667},"nbformat":4,"nbformat_minor":0}
